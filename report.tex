\documentclass[pdftex,ptm,12pt,a4paper]{report}
\renewcommand{\baselinestretch}{1.5}
\setcounter{secnumdepth}{5}
\usepackage[english, russian]{babel}

% PDF search & cut'n'paste
\usepackage{cmap}
\usepackage[table,xcdraw]{xcolor}
\renewcommand{\baselinestretch}{1.5}
\usepackage{setspace}
\usepackage{indentfirst}

% Cyrillic support
\usepackage{mathtext}
\usepackage{amsmath}
\usepackage[T1,T2A]{fontenc}
\DeclareSymbolFont{T2Aletters}{T2A}{cmr}{m}{it}
\usepackage[utf8]{inputenc}
\usepackage{multicol}

\usepackage[bottom=30mm,top=20mm,right=20mm,left=30mm,headsep=0cm,nofoot]{geometry}

\usepackage{calc}
\setlength{\footskip}{\paperheight
  -(1in+\voffset+\topmargin+\headheight+\headsep+\textheight)
  -0.75in}

\usepackage{array}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\makeatletter
\renewcommand*{\ps@plain}{%
  \let\@mkboth\@gobbletwo
  \let\@oddhead\@empty
  \def\@oddfoot{%
    \reset@font
    \hfil
    \thepage
    % \hfil % removed for aligning to the right
  }%
  \let\@evenhead\@empty
  \let\@evenfoot\@oddfoot
}
\makeatother
\pagestyle{plain}

\usepackage[pdftex]{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[russian,english]{babel}
    \addto{\captionsenglish}{\renewcommand{\bibname}{Литература}}
    \addto\captionsenglish{\renewcommand{\figurename}{Рис.}}
    \addto\captionsenglish{\renewcommand{\contentsname}{Содержание}}
    \addto\captionsenglish{\renewcommand{\proofname}{Доказательство}}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{url}
\usepackage{abstract}
\usepackage{float}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\renewcommand*{\proofname}{Доказательство}
\usepackage{indentfirst}
\usepackage{color}
\usepackage{natbib}
\usepackage{bbm, dsfont}


% Detect whether PDFLaTeX is in use
\usepackage{ifpdf}

% Fix links to floats
\usepackage[all]{hypcap}

\makeatletter
\renewcommand{\@chapapp}{Часть}
\makeatother

% Theorem Styles
\newtheorem{theorem}{Теорема}[chapter]
\newtheorem{lemma}[theorem]{Лемма}
\newtheorem{claim}[theorem]{Теорема}
% Definition Styles
\theoremstyle{definition}
\newtheorem{definition}{Определение}[chapter]
\newtheorem{example}{Пример}[chapter]
% Rule for Title Page
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}

\begin{titlepage}
\newpage

\begin{center}
МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ РОССИЙСКОЙ ФЕДЕРАЦИИ \\
\vspace{0.5cm}
ГОСУДАРСТВЕННОЕ ОБРАЗОВАТЕЛЬНОЕ УЧРЕЖДЕНИЕ \\*
ВЫСШЕГО ПРОФЕССИОНАЛЬНОГО ОБРАЗОВАНИЯ\\*
"МОСКОВСКИЙ ФИЗИКО-ТЕХНИЧЕСКИЙ ИНСТИТУТ \\*
(ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ)" \\*
\vspace{0.5cm}
ФАКУЛЬТЕТ ИННОВАЦИЙ И ВЫСОКИХ ТЕХНОЛОГИЙ \\*
КАФЕДРА АНАЛИЗА ДАННЫХ \\*
\hrulefill
\end{center}


\vspace{3em}

\begin{center}
\Large Выпускная квалификационная работа по направлению 01.03.02 <<Прикладная математика и информатика>> \linebreak НА ТЕМУ:
\end{center}

\vspace{2.5em}

\begin{center}
\textsc{\large{\textbf{Алгоритмы консенсуса на энергонезависимой памяти произвольного доступа}}}
\end{center}

\vspace{6.5em}

\begin{minipage}{.45\linewidth}
\begin{flushleft}
Студент \\ Научный руководитель к.ф-м.н \\ Зам. зав. кафедрой д.ф-м.н, проф.
\end{flushleft}
\end{minipage}
\hfill
\begin{minipage}{.45\linewidth}
\begin{flushright}
    Сурин М.С.\\ Бабенко А.В.\\Бунина Е.И.
\end{flushright}
\end{minipage}

\vspace{\fill}

\begin{center}
МОСКВА, 2017
\end{center}

\end{titlepage}

\tableofcontents
\sloppy

\setstretch{1.5}
\parindent=1.25cm

\chapter{Введение}
\section{NVDIMM}
Дизайн СУБД всегда был вынужден принимать во внимание принципиальную разницу между энергозависимыми устройствами хранения информации и энергонезависимыми.
Разница проявляется как в латентности доступа, так и в особенностях предоставляемого интерфейса. Энергонезависимые устройства как правило предоставляют блочный интерфейс, то есть
позволяют оперировать только блоками из тысяч байт. В то время как современные DIMM дают возможность оперировать словами -- единицами байт.
Но не так давно (2014-15гг) появились на рынке технологии под общим названием “NVDIMM”, занимающие некое промежуточное звено сохраняя данные при потере питания, предоставляя скорость доступа, сравнимую с DRAM и также давая возможность адресации отдельных байтов.

Большая часть продуктов на 2014г (например продукты Miron Technology) представляют из себя модуль DRAM служащий кешeм для модуля энергонезависимой памяти (как правило NAND FLASH)
и автономным источником питания. Но тогда же были анонсированы, а позже и появились на рынке устройства без подобного разделения -- к примеру Intel Optane NVDIMM \cite{peng2019system}.

Порядки времён доступа к промышленным устройствам:
\begin{center}
\begin{tabular} {|l| c c c|}
\hline
    & SSD & NVDIMM & DIMM \\
    \hline
чтение & 200us & 120ns & 80ns \\
запись & 2ms & 750ns & 80ns \\
\hline
\end{tabular}
\end{center}

Такая небольшая разница между быстрой оперативной памятью и медленной энергонезависимой даёт возможность пересмотреть традиционные подходы к дизайну и архитектуре СУБД в перспективе давая возможность добиться большей производительности.

\section{Обзор литературы}
Несмотря на отсутствие на рынке устройств, исследователи давно пытаются оптимизировать алгоритмы \cite{iwabuchi2014nvm} и структуры данных \cite{chen2015persistent} для персистентной памяти .
Многие из них пользуются либо программными платформами для эмуляции задержек NVDIMM \cite{sengupta2015framework} либо занимаются построением аппаратных моделей \cite{dong2012nvsim}.
Использование персистентной памяти ставит перед исследователями новые задачи, такие как менеджмент памяти \cite{schwalb2015nvm}. Также своя специфика есть у задачи обеспечения
целостности данных при потере питания, так как большинство современных процессоров кешируют доступы к памяти и практически не предоставляют примитивов для управления своим кешем.
Как следствие для работы с персистентной памятью появились отдельные библиотеки такие как PMDK \cite{pmdk} и api \cite{kolli2016delegated}.
Задачей построения архитектуры СУБД, занимается удивительно малое количество исследователей и в основном можно выделить исследователей из Carnegie Mellon School of Computer Science
\cite{pavlo17}, \cite{arulraj2015let}, \cite{debrabant2014prolegomenon}, \cite{arulraj2017build}, \cite{writebehind}.  В \cite{writebehind} приведeна альтернатива write-ahead logging
для NVM, позволяющая повысить производительность СУБД и рассмотрена задача репликации с учётом NVM, но задача координации не рассматривалась.
Задачей исследования алгоритмов консенсуса для NVM по нашим сведениям никто не занимался.

\chapter{Цель работы}
\section{Постановка задачи}
Мы рассматриваем алгоритмы консенсуса с точки зрения задачи репликации состояния конечного автомата. Состояние будет представлять из себя ассоциативный массив, ключами и значениями
выступают произвольные последовательности байт. Зафиксируем интерфейс, достаточный для большинства прикладных задач:
\begin{itemize}
    \item get($key$) -- операция чтения значения по ключу
    \item set($key$, $value$) -- операция записи значения по ключу
    \item compare\_and\_set($key$, $value_1$, $value_2$) -- операция обновления значения по ключу $key$ на $value_2$ в случае если оно до операции равно $value_1$
\end{itemize}

От алгоритмов будем требовать линеаризуемости \cite{linearizability} истории операций в условиях наличия нарушений связности сети.

\section{Метрики}
При экспериментах мы изучаем следующие характеристики:
\begin{itemize}
    \item латентность записи (то есть операций set и compare\_and\_set)
    \item скорость восстановления отставших реплик
\end{itemize}

В большинстве прикладных реализаций алгоритмов репликации операции чтения осуществляются лидером без задействия реплик из оперативной памяти.
А значит, от алгоритмов оптимизированных для NVM нет поводов ожидать улучшений латентности чтения. Поэтому в нашей работе данную метрику не исследуем.

\section{Бейзлайн}
В качестве эталонной реализации мы используем реализацию алгоритма RAFT \cite{raftpaper} использующую NVDIMM как блочное устройство
хранящую на ней write-ahead log и снепшоты состояния.

Напомним некоторые детали общей схемы работы данного алгоритма:


Также были реализованы следующие оптимизации не меняющие принципиальной схемы работы:
\begin{itemize}
\item heartbeat осуществляется без задержки при клиентском запросе на запись
\item сброс write-ahead log на диск осуществляется фоновым процессом, но при обработке клиентских запросов лидером и обработке heartbeat репликами происходит без задержки.
\end{itemize}

\chapter{Постановка эксперимента}
\section{Инструменты}

Все эксперименты проводились в операционной системе Linux.  Для прикладного использования на данной платформе NVDIMM
после предварительной разметки и настройки представляет собой блочное устройство. Для использования в качестве памяти предполагается создание файла с помощью fallocate
и его отображение в виртуальную память с помощью mmap. Файловая система при этом должна предоставлять режим DAX, отключающий page-cache. Мы в частности использовали Ext4.
После вышеописанных шагов модификации выделенного пространства на NVDIMM не требуют системных вызовов и не задействуют ядро операционной системы.

Записи в NVDIMM кешируются процессором. Для отказоустойчивой записи необходимо вытеснить соответствующие участки памяти из кэша одной из инструкций clflush/clflushopt/clwb
и подождать барьер записи -- например выполнить инструкцию sfence. При этом механизмов предотвращающих преждевременное вытеснение памяти из процессорного кэша нет.
NVDIMM при этом гарантирует атомарность модификации участков памяти, соответствующих кеш-линиям.

В своих экспериментах мы используем библиотеку PMDK, предоставляющую коллекцию базовых примитивов для работы с персистентной памятью.
К примеру такие как указатели на персистентную память, механизм выделения памяти и транзакции в персистентной памяти. О них мы и поговорим подробнее.

В силу механизма отображения персистентной памяти в виртуальную, персистентная память может быть доступна прикладным программам с разным смещением в разных запусках.
А значит, при необходимости использования ссылок на персистентную память необходимо оперировать не указателями, а смещениями внутри персистентного региона памяти.

\label{allocations}
Задача управления персистентной памятью также имеет свою специфику: выделение памяти и запись ссылки на неё в уже выделенную область памяти должны происходить атомарно, так как
при пропаже питания между этими двумя действиями может образоваться утечка памяти. Утечки персистентной памяти наносят гораздо больший вред чем утечки оперативной,
так как не исчезают после перезапуска программы. Механизм выделения памяти в PMDK использует транзакции.

Транзакция в персистентной памяти это атомарное изменение нескольких участков памяти. Отдельно подчеркнём что мы говорим не про атомарность изменения для других процессорных ядер, а
про атомарность изменения в случае сбоя питания.
Обобщённая схема механизма транзакций в PMDK такова:
\begin{enumerate}
    \item модифицируемые регионы копируются в undo log -- примитив реализованный в библиотеке libpmemlog.
    \item модифицируются исходные участки памяти
    \item удаляется запись из undo log
\end{enumerate}
На каждом из шагов все записи отказоустойчиво фиксируются в персистентной памяти (то есть вытесняются из процессорного кеша и ожидается барьер записи).

\section{Структуры данных}
Для уменьшения латентности записи мы отказываемся от write-ahead log и модифицируем структуры данных сразу при обработке пользовательских запросов лидером
и обработке heartbeat репликами. Все структуры данных в наших экспериментах в том или ином виде реализуют сортированный ассоциативный массив.
Мы пользуемся MVCC \cite{bernstein1983multiversion} храня несколько версий значений -- ключами в этом массиве выступают пары (пользовательский ключ, raft timestamp).
Также для каждой неподтверждённой кворумом транзакции мы храним запись для отката со списком указателей на её ключи. Ключ для каждой такой записи имеет вид
(зарезервированная строка, timestamp транзакции).
Для операции $get(x)$ мы выполняем поиск наибольшего ключа не превосходящего (x, applied\_ts) где applied\_ts -- номер последней применённой транзакции в терминах raft.
Для операции $compare\_and\_set(x, value_1, value_2)$ соответственно выполняем поиск максимального ключа вида $(x, y).$

При работе алгоритма лидер хранит в DRAM некоторое небольшое количество записей соответствующих последним обработанным транзакциям для пересылки репликам.
Следуя общей схеме алгоритма RAFT лидер с некоторой периодичностью пытается переслать эти записи репликам. В случае значительного отставания какой-либо реплики, она не может
принять записи из вышеописанного буфера, так как получала промежуточных записей от лидера. Для эффективного решения задачи восстановления таких реплик все реализованные нами
структуры данных имеют механизм снимков состояния для последующей пересылки отставшей реплике состояния лидера целиком.

В качестве структуры данных реализующей ассоциативный массив мы пробовали персистентные B+ деревья. В наших тестовых сценариях размер базы составлял сотни тысяч ключей и
оптимально с точки зрения производительности себя показали деревья с фактором ветвления 4-7.

Также были реализованы персистентные односвязные списки. Для ускорения операций чтения в DRAM поддерживается сбалансированное дерево поиска со ссылками на вершины данного списка.
Модификации (как записи так и удаления) в данной структуре данных реализованы добавлением в конец списка и соответствующими модификациями дерева в DRAM.
Подчеркнём сходство данной схемы с классическим write-ahead log. Ключевое отличие данной структуры данных в возможности очистки такого списка от дубликатов ключей фоновым
процессом без блокировки процесса чтений и модификаций и значительной нагрузки на устройство хранения. Снимком данной структуры данных является односвязный список.
В нашей реализации взятие снимка блокирует процесс очистки структуры данных от дубликатов.

\section{Управление памятью}
Как упоминалось в \ref{allocations}, управление персистентной памятью представляет из себя нетривиальную задачу.
В отличие от PMDK мы реализовали систему с автоматической сборкой мусора, что позволяет не ждать барьеров памяти при каждой модификации структуры данных, а делать это для
групп модификаций. Здесь подчеркнём что мы можем позволить себе гораздо меньшие размеры таких групп чем в случае использования write-ahead logging. Ниже опишем общую схему реализации:

При инициализации базы мы размечаем всю доступную персистентную память на страницы -- в наших тестах оптимально себя показали размеры порядка 1K.
В начале каждой страницы находится контрольный блок -- указатель на свободную память в этой странице и указатель на следующую в общем односвязном списке страниц.

\section{Алгоритм}

\chapter{Результаты}

\chapter{Заключение}

\bibliography{report}
\bibliographystyle{plain}


\end{document}
